# ðŸ§  SmartManuals-AI

**Local Semantic Q&A for Equipment Manuals and Part Catalogs**  
Built by [Damilare Eniolabi](mailto:damilareeniolabi@gmail.com) | GitHub: [@damoojeje](https://github.com/damoojeje)

---

SmartManuals-AI is a fully local RAG (Retrieval-Augmented Generation) pipeline that lets you ask intelligent questions from user manuals, service guides, parts catalogs, diagrams, and engineering drawings â€” **without any internet connection or cloud model**.

---

## âœ… Features

- ðŸ“š Ingests and parses PDF manuals, images, and part tables
- ðŸ§© Converts data into searchable chunks and structured parts
- ðŸ§  Embeds using `sentence-transformers` into a local ChromaDB
- ðŸ’¬ Answers natural questions using local Ollama models like `llama3`, `mistral`, or `gemma3`
- ðŸ–¥ï¸ Simple Gradio dashboard for demo and interaction
- ðŸ§  Supports OCR, tables, and semantic search

---

## ðŸš€ Quickstart

### ðŸ“¦ Install dependencies
```bash
pip install -r requirements.txt
```

### âš™ï¸ Configure `.env`
Make sure `.env` is in your root folder and sets paths, model, and keyword options.

### ðŸ“ Add PDFs
Drop your manuals into the `Manuals/` folder.

### ðŸ—ï¸ Run the full pipeline
```bash
# Extract chunks, tables, images
python extract_text_and_tables.py

# Embed into Chroma
python embed_chunks_to_chroma.py

# Launch dashboard
python dashboard.py
```

> Or run everything with:
```bash
./run_all.sh      # macOS/Linux
run_all.bat       # Windows
```

---

## ðŸ–¥ï¸ Project Structure
```
SmartManuals-AI/
â”œâ”€â”€ Manuals/                # Your input folder
â”œâ”€â”€ chroma_store/          # Local vector DB
â”œâ”€â”€ images/                # OCR'd or extracted images
â”œâ”€â”€ .env                   # All config values
â”œâ”€â”€ chunks.jsonl           # Text + table chunks (auto)
â”œâ”€â”€ tables.json            # Parsed tables (auto)
â”œâ”€â”€ image_metadata.json    # OCR'd images (auto)
â”œâ”€â”€ extract_text_and_tables.py
â”œâ”€â”€ embed_chunks_to_chroma.py
â”œâ”€â”€ query_ollama_rag.py
â”œâ”€â”€ dashboard.py
â”œâ”€â”€ run_all.bat / run_all.sh
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ SETUP_GUIDE.md
â””â”€â”€ README.md
```

---

## â“ Example Queries

- "How do I access diagnostics on the Discover SE3 console?"
- "What does part A132-7 refer to?"
- "Where is the fuse on the Everest model?"
- "How do I immobilize the console for transport?"

---

## ðŸ¤– Powered by
- ðŸ§  [Ollama](https://ollama.com/) â€“ local LLM serving
- ðŸ” [ChromaDB](https://www.trychroma.com/) â€“ vector search
- ðŸ§  [Sentence Transformers](https://www.sbert.net/)
- ðŸ–¼ï¸ [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)
- ðŸŒ [Gradio](https://gradio.app/) â€“ web interface

---

## ðŸ“¬ Contact
**Author**: [Damilare Eniolabi](mailto:damilareeniolabi@gmail.com)  
**GitHub**: [@damoojeje](https://github.com/damoojeje)

> Built for private, offline, and high-trust document intelligence.
